<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Skell-E HTML Preview</title>
  <link rel="stylesheet" href="../assets/style.css">
</head>
<body>
  <article>
    <header>
        <h1 id="title">Why I Use Gemini LLM For All Of My Apps (And NOT OpenAI + Anthropic)</h1>
        <a href="#" class="button copy-link" onclick="copyToClipboard(); return false;">Copy Code</a>
    </header>
    <main id="code-to-copy" class="container">
<h2>Gemini's Performance Suits My Needs</h2>

<p>People are often surprised when I say I use <strong>Gemini</strong> as my primary LLM for building SaaS applications. Despite not being an AI expert, I've found that Gemini's performance is <strong>good enough</strong> for what I need. I believe many overemphasize performance metrics, focusing on benchmarks that may not reflect real-world applications. In my experience, most LLMs today are <strong>extremely capable</strong>, and the differences are <strong>minuscule</strong> for typical use cases.</p>

<p>Currently, I'm building two SaaS products:</p>

<ul>

<li><strong>Monty</strong>: An AI-powered notetaker that records meetings, summarizes them, and allows users to chat with the meeting transcripts for deeper insights.</li>

<li><strong>Perfect Interview</strong>: An AI-driven interview prep tool that generates custom interview questions and suggests answers based on a user's resume and the job description.</li>

</ul>

<p>In both applications, I use <strong>Gemini 2.0 Flash</strong> for generating summaries, answering questions, and providing real-time interview assistance. The outputs have been consistently reliable, and from an <strong>eyeball test</strong>, Gemini performs admirably.</p>

<h2>Cost Savings with Gemini</h2>

<p>One significant advantage of Gemini is its <strong>competitive pricing</strong> compared to other models:</p>

<ul>

<li><strong>OpenAI GPT-4 Vision</strong>: $0.15 per 1K tokens (input), $0.60 per 1K tokens (output)</li>

<li><strong>Anthropic Claude 3.5</strong>: $0.80 per 1K tokens (input), $4.00 per 1K tokens (output)</li>

<li><strong>Gemini 2.0 Flash</strong>: <strong>$0.10 per 1K tokens (input), $0.40 per 1K tokens (output)</strong></li>

</ul>

<p>The <strong>cost savings</strong> with Gemini are substantial. For me, these savings <strong>outweigh the marginal differences in performance</strong>. When scaling applications, the lower costs make Gemini the <strong>best bang for your buck</strong> among LLMs.</p>

<h2>Enhanced Developer Experience</h2>

<p>I appreciate the <strong>developer experience</strong> that Gemini offers. It's the most <strong>truly multimodal</strong> LLM available, accepting a wide range of input types:</p>

<ul>

<li><strong>Text files</strong></li>

<li><strong>PDFs</strong></li>

<li><strong>Images</strong></li>

<li><strong>Videos</strong></li>

</ul>

<p>This flexibility allows me to input almost any file into the <strong>Gemini Chat Completion API</strong>. While OpenAI and Anthropic support vision inputs, they currently lack support for video.</p>

<p>Additionally, Gemini boasts a <strong>massive context window</strong> of <strong>1 million tokens</strong>, which is <strong>significantly larger</strong> than what other models offer. This large context window simplifies development, as I can <strong>input extensive context without managing state</strong>, enabling more straightforward one-shot outputs.</p>

<p style="text-align: center;">* * *</p>

<p>Overall, Gemini stands out due to its <strong>cost-efficiency</strong>, <strong>multimodal capabilities</strong>, and <strong>developer-friendly features</strong> like the large context window. While I was initially skeptical, my hands-on experience has made Gemini my <strong>default LLM</strong> for building apps.</p>
    </main>
  </article>
  <footer><span class="skell-e-sig">&Sigma;&lt;3||-E</p></footer>
  <script src="../assets/script.js"></script>
</body>
</html>