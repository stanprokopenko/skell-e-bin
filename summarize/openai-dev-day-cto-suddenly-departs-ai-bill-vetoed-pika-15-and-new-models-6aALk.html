<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Skell-E HTML Preview</title>
  <link rel="stylesheet" href="../assets/style.css">
</head>
<body>
  <article>
    <header>
        <h1 id="title">OpenAI Dev Day, CTO Suddenly Departs, AI Bill Vetoed, Pika 1.5, and New Models!</h1>
        <a href="#" class="button copy-link" onclick="copyToClipboard(); return false;">Copy Code</a>
    </header>
    <main id="code-to-copy" class="container">
<h2>OpenAI Dev Day Highlights</h2>

<p>This week, OpenAI held their Dev Day and made several exciting announcements.</p>

<p><strong>Real-time Voice API</strong></p>

<p>They introduced a new <strong>Real-time Voice API</strong>. Now, developers can build fast speech-to-speech experiences into their applications, similar to ChatGPT's advanced voice mode. It supports natural conversations using six preset voices. The pricing is quite reasonable, costing about <strong>6 cents per minute of audio input</strong> and <strong>24 cents per minute of audio output</strong>.</p>

<p><strong>Fine-tuning Vision Models</strong></p>

<p>OpenAI also announced that you can now <strong>fine-tune Vision models</strong> through their API. This allows developers to customize models for stronger image understanding. Applications include enhanced visual search, better object detection for autonomous vehicles, and improved medical image analysis. They offer <strong>1 million training tokens per day for free</strong> until August 31, 2024.</p>

<p><strong>Prompt Caching</strong></p>

<p>They introduced <strong>prompt caching</strong>, which lets developers reduce cost and latency by reusing recently seen input tokens. This offers a <strong>50% discount and faster prompt processing times</strong>. Caches are typically cleared after 5 to 10 minutes of inactivity and always within one hour of last use.</p>

<p><strong>Model Distillation</strong></p>

<p>OpenAI is now offering <strong>model distillation</strong> in their API. This means you can fine-tune a cost-efficient model using the outputs of a larger model. It includes three core concepts: <strong>stored completions</strong>, <strong>evals</strong>, and <strong>fine-tuning</strong>. It's like using a big model to train a smaller one, saving on costs and improving efficiency.</p>

<h2>OpenAI's Structural Changes</h2>

<p>In other news, OpenAI is moving away from its nonprofit status. According to a Reuters exclusive, they plan to restructure their core business into a <strong>for-profit benefit corporation</strong>. This means they'll no longer be controlled by a nonprofit board. There has been some controversy around CEO <strong>Sam Altman</strong> receiving equity, but we'll have to wait and see how it unfolds.</p>

<h2>Leadership Departures at OpenAI</h2>

<p>Several leaders have left OpenAI recently. <strong>Mira Murati</strong>, the CTO, left suddenly without giving prior notice. Also, Bob and Barrett have decided to depart. While this talent drain is significant, I believe OpenAI still has a strong team and will continue to innovate.</p>

<h2>California's AI Bill Vetoed</h2>

<p>Great news from California: Governor <strong>Gavin Newsom</strong> vetoed the new AI bill that was almost set to become law. Many AI experts opposed the bill, saying it was too broad and early. I agree that it's too soon to regulate AI heavily. Overregulation could stifle innovation, much like what's happening in the EU.</p>

<h2>New Releases and Updates</h2>

<p><strong>Pika Labs</strong> released <strong>Pika 1.5</strong>, which creates stunning videos. The quality is impressive, and it looks like something straight out of a Pixar movie.</p>

<p>There was some drama in the open-source community. <strong>Pair AI</strong>, a YC-backed company, forked a well-known open-source product but mishandled the licenses. They admitted their mistake and are working to fix it. It's a good reminder of the importance of respecting open-source licenses.</p>

<p>I've also been waiting for updates from <strong>Matt Shumer</strong> regarding the Reflection 70B model. We haven't heard anything in over three weeks. I hope they communicate soon.</p>

<p>Lastly, <strong>Liquid AI</strong> introduced <strong>Liquid Foundation Models (LFMs)</strong> in 1B, 3B, and 40B sizes. These models perform exceptionally well and aren't Transformer-based. I'm looking forward to testing them, but I'm cautiously optimistic.</p>

<p style="text-align: center;">* * *</p>

<p>It's been an exciting week with lots of developments in the AI world. From OpenAI's announcements to new models and some industry drama, there's plenty to keep an eye on. As always, innovation continues to push forward, and I can't wait to see what's next.</p>
    </main>
  </article>
  <footer><span class="skell-e-sig">&Sigma;&lt;3||-E</p></footer>
  <script src="../assets/script.js"></script>
</body>
</html>