<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Skell-E HTML Preview</title>
  <link rel="stylesheet" href="../assets/style.css">
</head>
<body>
  <article>
    <header>
        <h1 id="title">The Hidden Autopilot Data That Reveals Why Teslas Crash | WSJ</h1>
        <a href="#" class="button copy-link" onclick="copyToClipboard(); return false;">Copy Code</a>
    </header>
    <main id="code-to-copy" class="container">
<p>On May 5, 2021, <strong>Steven Hendrickson</strong> was driving his Tesla Model 3 in Autopilot mode through Fontana, California. At around 2:30 AM, an <strong>overturned semi-truck</strong> appeared ahead. Moments later, Hendrickson was killed when his car failed to stop. He left behind his wife and two children.</p>

<p>This tragic incident is one of over a <strong>thousand crashes</strong> involving Tesla's Autopilot reported to federal regulators since 2021. Concerns are growing that Tesla's reliance on <strong>camera-based systems</strong> for Autopilot, rather than a combination of sensors like other automakers use, is putting the public at risk.</p>

<h2>Autopilot Crashes and Fatalities</h2>

<p>Teslas operating in Autopilot have been involved in <strong>hundreds of crashes</strong> across the U.S. since 2016. The Wall Street Journal analyzed data and found:</p>

<ul>

<li><strong>222 crashes</strong> were pieced together from Tesla's submissions.</li>

<li><strong>44 incidents</strong> involved Teslas veering suddenly.</li>

<li><strong>31 incidents</strong> occurred when Autopilot failed to stop or yield for obstacles.</li>

</ul>

<p>Notable crashes include:</p>

<ul>

<li>In Orlando, Florida, a Model 3 crashed into a stopped police car attending to a disabled vehicle.</li>

<li>In Guadalupe County, Texas, a Model 3 ran through an intersection and off the road.</li>

</ul>

<p>These <strong>failure-to-stop crashes</strong> have resulted in the most serious injuries and deaths.</p>

<h2>The Limitations of Camera-Based Systems</h2>

<p>Tesla's Autopilot relies mainly on <strong>cameras and computer vision</strong>, with radar backup in some models. Unlike other automakers that use a combination of radar, cameras, and <strong>lidar</strong> (laser ranging technology), Tesla has chosen to exclude expensive sensors.</p>

<p>According to experts, camera-based systems can struggle with:</p>

<ul>

<li>Recognizing <strong>unusual obstacles</strong> not present in their training data.</li>

<li><strong>Calibration issues</strong> between multiple cameras, leading to inconsistent object detection.</li>

</ul>

<p>In one crash near Los Angeles in 2021, a Tesla failed to recognize a crashed pickup truck because its cameras did not provide consistent information.</p>

<h2>Expert Criticism and Investigations</h2>

<p><strong>Missy Cummings</strong>, a leading expert on autonomous driving, warned in 2016 about the risks of semi-autonomous vehicles: "There is no question that someone is going to die in this technology."</p>

<p>The <strong>National Highway Traffic Safety Administration (NHTSA)</strong> has launched investigations into Autopilot but has released little information, and Teslas remain on the road. In 2021, NHTSA required automakers to report all serious crashes involving semi-autonomous systems, but much of Tesla's data is considered proprietary and hidden from the public.</p>

<h2>Drivers' Overreliance and Lack of Data Transparency</h2>

<p>Drivers like Steven Hendrickson had <strong>high confidence</strong> in Autopilot. His wife, Janell, shared that he trusted the system with his life and their children's lives. Tesla advises that drivers need to be ready to take control at all times, stating that Hendrickson was warned <strong>19 times</strong> to keep his hands on the wheel before the crash.</p>

<p>Accessing detailed data from Tesla after crashes is <strong>difficult</strong>. Families and experts struggle to obtain internal video and data to understand how Autopilot performed. Tesla maintains control over this information, citing proprietary reasons.</p>

<p style="text-align: center;">* * *</p>

<p>The reliance on camera-based technology in Tesla's Autopilot presents <strong>significant risks</strong>. As we witness more incidents and investigations, it's clear that this technology has limitations that need addressing. Drivers should <strong>understand their car's capabilities</strong> and remain vigilant, even when using advanced systems like Autopilot. The future of semi-autonomous driving requires a <strong>reassessment</strong> of current technologies to ensure public safety.</p>
    </main>
  </article>
  <footer><span class="skell-e-sig">&Sigma;&lt;3||-E</p></footer>
  <script src="../assets/script.js"></script>
</body>
</html>