<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Skell-E HTML Preview</title>
  <link rel="stylesheet" href="../assets/style.css">
</head>
<body>
  <article>
    <header>
        <h1 id="title">OpenAI o3 & o4-mini</h1>
        <a href="#" class="button copy-link" onclick="copyToClipboard(); return false;">Copy Code</a>
    </header>
    <main id="code-to-copy" class="container">
<h2>A Qualitative Step into the Future</h2>

<p>Greg Brockman and Mark Chen from OpenAI have announced the release of <strong>O3 and O4 Mini</strong>, AI models that produce legitimately good and useful novel ideas. These models are <strong>AI systems trained to use tools</strong>, enhancing their reasoning and problem-solving abilities.</p>

<h2>Tool Use Enhances Reasoning</h2>

<p>By training these models to use tools, they become smarter and more powerful. For example, they can use calculators for difficult math problems or manipulate images using Python. They also perform complex coding tasks and navigate real codebases more efficiently than before.</p>

<h2>State-of-the-Art Results</h2>

<p>Combining the O series reasoning models with a full suite of tools has led to <strong>state-of-the-art results</strong> across challenging benchmarks, including <strong>Amy</strong>, <strong>GPQA</strong>, <strong>Codeforces</strong>, and <strong>SweetBench</strong>. These advancements are powered by continued algorithmic improvements in their reinforcement learning (RL) paradigm.</p>

<h2>Demonstrations</h2>

<p>Brandon McKenzie and Eric Mitchell showcased the capabilities of O3 and O4 Mini:</p>

<p><strong>Science Example</strong>: Brandon asked O3 to analyze a physics poster from his 2015 internship estimating the proton isovector scalar charge. Despite the result not being in the poster, the model extrapolated data, searched recent literature, and provided accurate comparisons.</p>

<p><strong>Personalized Information</strong>: Eric enabled memory for O3, allowing it to know his interests. He asked the model to read the news and teach him something he didn't know but would find interesting. Knowing his interests in scuba diving and music, the model found a study where researchers use recordings of healthy coral reefs to accelerate regeneration by playing them underwater.</p>

<h2>Training and Scaling</h2>

<p>Wenda and Ana discussed the development of these models. They invested over ten times the training compute of previous models to produce O3. As they scaled up compute, performance on evaluations like Amy improved significantly. The models organically learn strategies like simplifying solutions, double-checking answers, and explaining reasoning without explicit training.</p>

<h2>Practical Coding Benchmarks</h2>

<p>The models achieve <strong>state-of-the-art results</strong> on practical coding benchmarks like <strong>SweetBench</strong> and <strong>Polyglot</strong>. They can identify bugs in codebases, propose fixes, and test solutions autonomously.</p>

<h2>Multimodal Reasoning</h2>

<p>These models can <strong>think with images</strong>, allowing them to handle complex images, including blurry or upside-down ones. They can manipulate, crop, and transform images using Python in their chain of thought, leading to significant increases in multimodal capabilities.</p>

<h2>Codex CLI and Open Source Initiative</h2>

<p>OpenAI introduced <strong>Codex CLI</strong>, a lightweight interface to connect models to users' computers, a reference implementation for safely deploying code-executing agents. They are open-sourcing all the code, and have announced a <strong>$1 million open-source initiative</strong> to support projects using their latest models with Codex CLI.</p>

<h2>Availability</h2>

<p>Starting today, OpenAI is rolling out access to O3, O4 Mini, and O4 Mini High to ChatGPT Pro Plus team subscribers. These models will replace the previous generation, offering improved performance. They will also be available via the API, with tool usage capabilities to be released in the upcoming weeks.</p>

<p style="text-align: center;">* * *</p>

<p>These models represent a major step forward in OpenAI's mission to bring AGI to benefit all of humanity. They are useful for scientific applications and everyday tasks. We encourage users to explore their capabilities and are excited to see how they will be utilized.</p>
    </main>
  </article>
  <footer><span class="skell-e-sig">&Sigma;&lt;3||-E</p></footer>
  <script src="../assets/script.js"></script>
</body>
</html>