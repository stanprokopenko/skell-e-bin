<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Skell-E HTML Preview</title>
  <link rel="stylesheet" href="../assets/style.css">
</head>
<body>
  <article>
    <header>
        <h1 id="title">GPT-4.5 Fails. AGI Cancelled. It's all over...</h1>
        <a href="#" class="button copy-link" onclick="copyToClipboard(); return false;">Copy Code</a>
    </header>
    <main id="code-to-copy" class="container">
<h2>Not the Groundbreaking Upgrade We Expected</h2>

<p>I recently explored <strong>GPT-4.5</strong>, expecting a significant leap from GPT-4. However, it turned out to be a <strong>modest improvement</strong>. It doesn't excel in <strong>reasoning tasks</strong>, high-level math, or complex coding compared to top reasoning models like <strong>GPT-4 with enhancements</strong>.</p>

<h2>Performance and Speed</h2>

<p>Surprisingly, GPT-4.5 isn't <strong>faster</strong> than its predecessors. When I asked it to write a step-by-step outline on making pickles safely at home, it was notably <strong>slow</strong>. This sluggishness reminded me of models from over a year ago.</p>

<h2>Cost Concerns</h2>

<p>I assumed GPT-4.5 might be <strong>cheaper</strong> to use, especially for API applications. However, it's actually <strong>more expensive</strong>. The cost per million tokens is <strong>$75 for input</strong> and <strong>$150 for output</strong>, making it the most expensive model available. This is significantly higher than other models, which cost around $15 per million tokens.</p>

<h2>Hallucinations</h2>

<p>One touted improvement was <strong>fewer hallucinations</strong>. But testing showed that GPT-4.5's hallucination rate is <strong>similar to GPT-4's</strong>. In evaluations, GPT-4 had a hallucination rate of 0.52, while GPT-4.5 was at an unimpressive <strong>1 N</strong>, indicating no significant reduction.</p>

<h2>Reflections on Testing GPT-4.5</h2>

<p>During a <strong>four-hour live stream</strong>, I tested GPT-4.5 extensively but found <strong>nothing impressive</strong>. It failed to shine in areas where improvements were expected. Even Andrej Karpathy noted that each 0.5 increment represents a <strong>10x compute increase</strong>, yet the results didn't reflect such a massive boost.</p>

<h2>Insights on Scaling</h2>

<p>Karpathy mentioned that scaling laws suggest more compute should improve performance. GPT-4.5, trained with significantly more resources, should theoretically be better. However, we might be approaching a point of <strong>diminishing returns</strong>. The increased compute doesn't seem to equate to proportionally better performance.</p>

<h2>Comparing Outputs</h2>

<p>I compared outputs between GPT-4 and GPT-4.5 on creative tasks, like writing a <strong>Rick and Morty episode</strong>. GPT-4.5's version was more engaging and true to the show's style, but the differences were <strong>subtle</strong>. In tasks requiring <strong>plays on words</strong> or <strong>abstract thinking</strong>, GPT-4.5 performed better, but not dramatically so.</p>

<p style="text-align: center;">* * *</p>

<p>It seems GPT-4.5 might serve as a <strong>synthetic data factory</strong> for training future models rather than being a user-facing upgrade. The <strong>scaling</strong> approach may be hitting its limits, with <strong>diminishing returns</strong> on performance despite massive increases in compute. We'll have to wait and see how future <strong>reasoning models</strong> built on GPT-4.5 will perform to truly assess the impact.</p>
    </main>
  </article>
  <footer><span class="skell-e-sig">&Sigma;&lt;3||-E</p></footer>
  <script src="../assets/script.js"></script>
</body>
</html>